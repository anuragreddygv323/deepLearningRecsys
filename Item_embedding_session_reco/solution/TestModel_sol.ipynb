{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Layer, Dropout, Masking\n",
    "from keras.layers import GRU, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "#from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_WORKING_DIR = 'f:/dss18/item_embedding_session_reco/'\n",
    "PATH_TO_ORIGINAL_DATA = '././data/'\n",
    "PATH_TO_PROCESSED_DATA = '././pre-train/'\n",
    "file_2_tokenize_name = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_tr.txt'\n",
    "file_2_tokenize_name_test = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_ts.txt'\n",
    "tokenized_file_name = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_tr_tk.txt'\n",
    "tokenized_file_name_test = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_ts_tk.txt'\n",
    "tokenized_file_name_X = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_tr_tkX.txt'\n",
    "tokenized_file_name_Y = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_tr_tkY.txt'\n",
    "tokenized_file_name_test_X = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_ts_tkX.txt'\n",
    "tokenized_file_name_test_Y = PATH_TO_PROCESSED_DATA + 'rcs15_sesss_ts_tkY.txt'\n",
    "glove_vectors_file_name = PATH_TO_PROCESSED_DATA + 'vectors_s_rcs15.txt'\n",
    "glove_vocab_file_name = PATH_TO_PROCESSED_DATA + 'rcs15_s_vocab.txt'\n",
    "vocab_size = 14386\n",
    "sessions_train = 781486\n",
    "sessions_test = 30726 \n",
    "sequence_length = 3\n",
    "sequence_len = 3\n",
    "embedding_size = 50\n",
    "do_val = 0.2\n",
    "n_samples = 10\n",
    "hidden_neurons = 30  #RNN layer output dim\n",
    "num_iter = 20\n",
    "N = 10  #recall@\n",
    "maxW = N+3   #max item clicke we count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, nb_classes=None):\n",
    "    '''Convert class vector (integers from 0 to nb_classes)\n",
    "    to binary class matrix, for use with categorical_crossentropy.\n",
    "    '''\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes),dtype=np.bool)\n",
    "    for i in range(len(y)):\n",
    "        idx = y[i,0]\n",
    "        Y[i, idx] = 1\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcRecall(recom,actual,i):\n",
    "    act_set = set(actual)\n",
    "    pred_set = set(recom[:i])\n",
    "    result = (float) (len(act_set & pred_set)) / float(len(act_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate GloVe vocabulary and vectors dictionary\n",
    "def generate(glove_vectors_file_name,glove_vocab_file_name):\n",
    "    with open(glove_vocab_file_name, 'r') as f:\n",
    "        words = [x.rstrip().split(' ')[0] for x in f.readlines()]\n",
    "    with open(glove_vectors_file_name, 'r') as f:\n",
    "        vectors = {}\n",
    "        for line in f:\n",
    "            vals = line.rstrip().split(' ')\n",
    "            vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
    "\n",
    "    vocab_size = len(words)\n",
    "    vocab = {w: idx for idx, w in enumerate(words)}\n",
    "    ivocab = {idx: w for idx, w in enumerate(words)}\n",
    "\n",
    "    vector_dim = len(vectors[ivocab[0]])\n",
    "    W = np.zeros((vocab_size, vector_dim))\n",
    "    for word, v in vectors.items():\n",
    "        if word == '<unk>':\n",
    "            continue\n",
    "        W[vocab[word], :] = v\n",
    "\n",
    "    # normalize each word vector to unit variance\n",
    "    W_norm = np.zeros(W.shape)\n",
    "    d = (np.sum(W ** 2, 1) ** (0.5))\n",
    "    W_norm = (W.T / d).T\n",
    "    return (W_norm, vocab, ivocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load voacab and vectors file to dict\n",
    "os.chdir(PATH_TO_WORKING_DIR)\n",
    "W, vocab, ivocab = generate(glove_vectors_file_name, glove_vocab_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before load test\n",
      "after load test\n"
     ]
    }
   ],
   "source": [
    "#load test files\n",
    "os.chdir(PATH_TO_WORKING_DIR)\n",
    "print(\"before load test\")\n",
    "\n",
    "#load first 3 clicks embedded vectors\n",
    "XTS = np.loadtxt(tokenized_file_name_test_X).reshape((sessions_test,sequence_len,embedding_size))\n",
    "test_size = int(XTS.shape[0])\n",
    "X_test = XTS[0:test_size, :]\n",
    "\n",
    "#load next user clicks id\n",
    "with open(file_2_tokenize_name_test, 'r') as f:\n",
    "    full_data = [line.rstrip().split(' ') for line in f]\n",
    "    data = full_data\n",
    "\n",
    "print(\"after load test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ebee0e70614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayer_from_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mlayer_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                        custom_objects=custom_objects)\n\u001b[1;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, layer_cache)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_or_create_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mget_or_create_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m             \u001b[0mlayer_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mlayer_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                        custom_objects=custom_objects)\n\u001b[1;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \"\"\"\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'output_dim'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#load and create model\n",
    "json_string = 'm3_10_my_model_architecture.json'\n",
    "json_file = open(PATH_TO_PROCESSED_DATA + json_string, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# load weights into new model\n",
    "weights_string = 'm3_10_my_model_weights.h5'\n",
    "model.load_weights(PATH_TO_PROCESSED_DATA +weights_string)\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use first 3 clicks to recommend\n",
    "Y_test = model.predict(X_test)\n",
    "recall = 0\n",
    "rown = 0\n",
    "rownc = 0\n",
    "recallV = [0]*N\n",
    "print(len(data))\n",
    "\n",
    "print(\"testing model \")\n",
    "for row in data:\n",
    "    if len(row) < 4:  #nothing to predict\n",
    "        rown = rown + 1\n",
    "        continue  #nothin to predict\n",
    "    \n",
    "    predicted_results = Y_test[rown]\n",
    "    dist = predicted_results\n",
    "    input_term = row[0:3]\n",
    "    for term in input_term: \n",
    "         if term in vocab:\n",
    "            index = vocab[term]\n",
    "            dist[index] = -np.Inf\n",
    "    top = np.argsort(-dist)[:N]\n",
    "    top_org = []\n",
    "    for glv_item_id in top:\n",
    "        org_item_id =ivocab[glv_item_id]\n",
    "        top_org.append(org_item_id)\n",
    "    top_org_set = set(top_org)\n",
    "    match = [click_id for click_id in row[3:maxW] if click_id in top_org_set]\n",
    "    recall = recall + (float (len(match))/ (float) (len(row[3:maxW])))\n",
    "    rownc = rownc+1\n",
    "    rown = rown + 1\n",
    "    for i in range(N):\n",
    "        recallV[i]= recallV[i] + calcRecall(top_org,row[3:maxW],(i+1))\n",
    "\n",
    "recall = (float) (recall)/(float) (rownc)\n",
    "print('recall ',recall)\n",
    "\n",
    "for i in range(N):\n",
    "    recallV[i] = (float)(recallV[i])/(float)(rownc)\n",
    "    print('recall@ '+ str(i+1) + ' ' + str(recallV[i])+\"\\n\")\n",
    "              \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
